---
title: "What Do We Really Want From Open Source AI?"
date: 2025-02-10T17:04:18+08:00
draft: true
---

Recently, the release of Deepseek sparked a discussion in the whole world. Especially, it was released under a MIT license, which excited open source builders like me.

However, people also questions the license, and whether Deepseek is really an open source project. Afterall, the so-called open-washing, the behavior of making a product looks like open sourced but in fact the otherwise, is too common so people became skeptical on new projects. Here are some precedences. OpenAI, the company behind ChatGPT, is ironically not "open" despite of its name sugguests. Llama, released by Meta under a customized meta license, which imposed certain restrictions on profiting with the model, is also considered not true open sourced.

People cite the newly defined OSI AI defintion as a checklist to determine if an AI project is considered open source. This includes releasing the model weights, source code for training the model, and input parameters for the traning code. The intention here is to let the users to reproduce the training process to obtain the same weights. However, the training data is not required to be released, due to the privacy and security concerns. OSI has been known for its focus on practicality.

All of these make me wonder, what makes a project open sourced? Why do we want that? Is the OSI AI defintion enough?

I remembered in 2013, I was excited by the beginning of MOOC. Lots of high-quality courses from the prestigious universities, just released for free. Andrew Ng, the founder of Coursera, instructed a Machine learning course. He proposed that GPU would be the future of machine learning. I also heard the term "Deep Learning" first time.

I was a new graduate of Finance major back then. I've explored different domain of statistics courses like economics, managements, psychology, and electrical engineering. Most of them build models to describe the data or draw smart conclusion from data. Machine learning is not too much different from that way in terms of predicting things from data. But it stands out from them with one idea, creating a program without manually writing it.

Now fastforward to 10 years later. Machine learning is no longer focusing on specific tasks like telling apple from oranges, and cats from dogs. Nowadays it is general purpose and it does everything. I've been practicing programming for almost 10 years. Nowadays I tell GPT what I want to write and then it spit out the code and I decide whether to apply. We'll soon see what Andrej Karpathy called the [vibe coding](https://x.com/karpathy/status/1886192184808149383), which you just accept everything and omakase to AI to do the rest.

The point here is that the AI model we're using is a special software. It takes some inputs and spits some outputs, but the behavior is no longer specified in the readable english, like the software in the traditional sense.

---

